# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details


# ruff: noqa: E402

# %% [markdown]
# # Guardians Report
# TODO: top level description

# %% [markdown]
# ## Imports

import os
from ecoscope_workflows_core.tasks.config import set_workflow_details
from ecoscope_workflows_core.tasks.filter import set_time_range
from ecoscope_workflows_core.tasks.groupby import set_groupers
from ecoscope_workflows_core.tasks.io import set_er_connection
from ecoscope_workflows_ext_ecoscope.tasks.results import set_base_maps
from ecoscope_workflows_ext_lion_guardians.tasks import load_map_files
from ecoscope_workflows_ext_lion_guardians.tasks import create_map_layers
from ecoscope_workflows_ext_ecoscope.tasks.io import get_subjectgroup_observations
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import process_relocations
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    relocations_to_trajectory,
)
from ecoscope_workflows_core.tasks.transformation import add_temporal_index
from ecoscope_workflows_ext_ecoscope.tasks.transformation import apply_classification
from ecoscope_workflows_core.tasks.groupby import split_groups
from ecoscope_workflows_core.tasks.transformation import sort_values
from ecoscope_workflows_ext_ecoscope.tasks.transformation import apply_color_map
from ecoscope_workflows_core.tasks.transformation import map_values_with_unit
from ecoscope_workflows_core.tasks.transformation import map_columns
from ecoscope_workflows_ext_ecoscope.tasks.results import create_polyline_layer
from ecoscope_workflows_core.tasks.skip import any_is_empty_df
from ecoscope_workflows_core.tasks.skip import any_dependency_skipped
from ecoscope_workflows_ext_ecoscope.tasks.analysis import summarize_df
from ecoscope_workflows_ext_ecoscope.tasks.io import persist_df
from ecoscope_workflows_ext_lion_guardians.tasks import combine_map_layers
from ecoscope_workflows_ext_lion_guardians.tasks import create_view_state_from_gdf
from ecoscope_workflows_ext_lion_guardians.tasks import zip_grouped_by_key
from ecoscope_workflows_ext_ecoscope.tasks.results import draw_ecomap
from ecoscope_workflows_core.tasks.io import persist_text
from ecoscope_workflows_core.tasks.results import create_map_widget_single_view
from ecoscope_workflows_core.tasks.skip import never
from ecoscope_workflows_core.tasks.results import merge_widget_views
from ecoscope_workflows_core.tasks.results import gather_dashboard

# %% [markdown]
# ## Set Workflow Details

# %%
# parameters

workflow_details_params = dict(
    name=...,
    description=...,
    image_url=...,
)

# %%
# call the task


workflow_details = (
    set_workflow_details.handle_errors(task_instance_id="workflow_details")
    .partial(**workflow_details_params)
    .call()
)


# %% [markdown]
# ## Time Range

# %%
# parameters

time_range_params = dict(
    since=...,
    until=...,
)

# %%
# call the task


time_range = (
    set_time_range.handle_errors(task_instance_id="time_range")
    .partial(time_format="%d %b %Y %H:%M:%S %Z", **time_range_params)
    .call()
)


# %% [markdown]
# ## Set Groupers

# %%
# parameters

groupers_params = dict(
    groupers=...,
)

# %%
# call the task


groupers = (
    set_groupers.handle_errors(task_instance_id="groupers")
    .partial(**groupers_params)
    .call()
)


# %% [markdown]
# ## Data Source

# %%
# parameters

er_client_name_params = dict(
    data_source=...,
)

# %%
# call the task


er_client_name = (
    set_er_connection.handle_errors(task_instance_id="er_client_name")
    .partial(**er_client_name_params)
    .call()
)


# %% [markdown]
# ## Base Maps

# %%
# parameters

base_map_defs_params = dict(
    base_maps=...,
)

# %%
# call the task


base_map_defs = (
    set_base_maps.handle_errors(task_instance_id="base_map_defs")
    .partial(**base_map_defs_params)
    .call()
)


# %% [markdown]
# ## Load local map files

# %%
# parameters

load_local_shapefiles_params = dict(
    config=...,
)

# %%
# call the task


load_local_shapefiles = (
    load_map_files.handle_errors(task_instance_id="load_local_shapefiles")
    .partial(**load_local_shapefiles_params)
    .call()
)


# %% [markdown]
# ## Create Map Layers

# %%
# parameters

create_custom_map_layers_params = dict(
    style_config=...,
)

# %%
# call the task


create_custom_map_layers = (
    create_map_layers.handle_errors(task_instance_id="create_custom_map_layers")
    .partial(file_dict=load_local_shapefiles, **create_custom_map_layers_params)
    .call()
)


# %% [markdown]
# ## Get Subject Group Observations from EarthRanger

# %%
# parameters

subject_group_observations_params = dict(
    subject_group_name=...,
)

# %%
# call the task


subject_group_observations = (
    get_subjectgroup_observations.handle_errors(
        task_instance_id="subject_group_observations"
    )
    .partial(
        client=er_client_name,
        time_range=time_range,
        raise_on_empty=False,
        include_details=False,
        include_subjectsource_details=False,
        **subject_group_observations_params,
    )
    .call()
)


# %% [markdown]
# ## Transform Observations to Relocations

# %%
# parameters

subject_relocations_params = dict()

# %%
# call the task


subject_relocations = (
    process_relocations.handle_errors(task_instance_id="subject_relocations")
    .partial(
        observations=subject_group_observations,
        relocs_columns=[
            "groupby_col",
            "fixtime",
            "junk_status",
            "geometry",
            "extra__subject__name",
            "extra__subject__subject_subtype",
            "extra__subject__sex",
        ],
        filter_point_coords=[
            {"x": 180.0, "y": 90.0},
            {"x": 0.0, "y": 0.0},
            {"x": 1.0, "y": 1.0},
        ],
        **subject_relocations_params,
    )
    .call()
)


# %% [markdown]
# ## Transform Relocations to Trajectories

# %%
# parameters

subject_trajectory_params = dict(
    trajectory_segment_filter=...,
)

# %%
# call the task


subject_trajectory = (
    relocations_to_trajectory.handle_errors(task_instance_id="subject_trajectory")
    .partial(relocations=subject_relocations, **subject_trajectory_params)
    .call()
)


# %% [markdown]
# ## Add temporal index to Subject Trajectories

# %%
# parameters

traj_add_temporal_index_params = dict()

# %%
# call the task


traj_add_temporal_index = (
    add_temporal_index.handle_errors(task_instance_id="traj_add_temporal_index")
    .partial(
        df=subject_trajectory,
        time_col="segment_start",
        groupers=groupers,
        cast_to_datetime=True,
        format="mixed",
        **traj_add_temporal_index_params,
    )
    .call()
)


# %% [markdown]
# ## Classify Trajectories By Speed

# %%
# parameters

classify_trajectory_speed_params = dict()

# %%
# call the task


classify_trajectory_speed = (
    apply_classification.handle_errors(task_instance_id="classify_trajectory_speed")
    .partial(
        df=traj_add_temporal_index,
        input_column_name="speed_kmhr",
        output_column_name="speed_bins",
        classification_options={"scheme": "equal_interval", "k": 6},
        label_options={"label_ranges": False, "label_decimals": 1},
        **classify_trajectory_speed_params,
    )
    .call()
)


# %% [markdown]
# ## Split Subject Trajectories by Group

# %%
# parameters

split_subject_traj_groups_params = dict()

# %%
# call the task


split_subject_traj_groups = (
    split_groups.handle_errors(task_instance_id="split_subject_traj_groups")
    .partial(
        df=classify_trajectory_speed,
        groupers=groupers,
        **split_subject_traj_groups_params,
    )
    .call()
)


# %% [markdown]
# ## Sort Trajetories By Classification

# %%
# parameters

sort_trajectories_speed_params = dict()

# %%
# call the task


sort_trajectories_speed = (
    sort_values.handle_errors(task_instance_id="sort_trajectories_speed")
    .partial(
        column_name="speed_bins",
        ascending=True,
        na_position="last",
        **sort_trajectories_speed_params,
    )
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Apply Color to Trajectories By Speed

# %%
# parameters

colormap_traj_speed_params = dict()

# %%
# call the task


colormap_traj_speed = (
    apply_color_map.handle_errors(task_instance_id="colormap_traj_speed")
    .partial(
        input_column_name="speed_bins",
        output_column_name="speed_bins_colormap",
        colormap=["#1a9850", "#91cf60", "#d9ef8b", "#fee08b", "#fc8d59", "#d73027"],
        **colormap_traj_speed_params,
    )
    .mapvalues(argnames=["df"], argvalues=sort_trajectories_speed)
)


# %% [markdown]
# ## Format Speedmap bins for legend

# %%
# parameters

speed_bin_legend_with_unit_params = dict()

# %%
# call the task


speed_bin_legend_with_unit = (
    map_values_with_unit.handle_errors(task_instance_id="speed_bin_legend_with_unit")
    .partial(
        input_column_name="speed_bins",
        output_column_name="speed_bins_formatted",
        original_unit="km/h",
        new_unit="km/h",
        decimal_places=1,
        **speed_bin_legend_with_unit_params,
    )
    .mapvalues(argnames=["df"], argvalues=colormap_traj_speed)
)


# %% [markdown]
# ## Format speed values for display

# %%
# parameters

speed_val_with_unit_params = dict()

# %%
# call the task


speed_val_with_unit = (
    map_values_with_unit.handle_errors(task_instance_id="speed_val_with_unit")
    .partial(
        input_column_name="speed_kmhr",
        output_column_name="speed_kmhr",
        original_unit="km/h",
        new_unit="km/h",
        decimal_places=1,
        **speed_val_with_unit_params,
    )
    .mapvalues(argnames=["df"], argvalues=speed_bin_legend_with_unit)
)


# %% [markdown]
# ## Rename columns for map tooltip display

# %%
# parameters

rename_speed_display_columns_params = dict()

# %%
# call the task


rename_speed_display_columns = (
    map_columns.handle_errors(task_instance_id="rename_speed_display_columns")
    .partial(
        drop_columns=[],
        retain_columns=[],
        rename_columns={
            "segment_start": "Start",
            "timespan_seconds": "Duration (s)",
            "speed_kmhr": "Speed (kph)",
            "extra__name": "Subject Name",
            "extra__sex": "Subject Sex",
        },
        **rename_speed_display_columns_params,
    )
    .mapvalues(argnames=["df"], argvalues=speed_val_with_unit)
)


# %% [markdown]
# ## Create map layer for each trajectory group

# %%
# parameters

traj_map_layers_params = dict(
    zoom=...,
)

# %%
# call the task


traj_map_layers = (
    create_polyline_layer.handle_errors(task_instance_id="traj_map_layers")
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"color_column": "speed_bins_colormap"},
        legend={
            "label_column": "speed_bins_formatted",
            "color_column": "speed_bins_colormap",
        },
        tooltip_columns=[
            "Start",
            "Duration (s)",
            "Speed (kph)",
            "Nighttime",
            "Subject Name",
            "Subject Sex",
        ],
        **traj_map_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=rename_speed_display_columns)
)


# %% [markdown]
# ## Subject summary table

# %%
# parameters

summary_trajectory_table_params = dict(
    reset_index=...,
)

# %%
# call the task


summary_trajectory_table = (
    summarize_df.handle_errors(task_instance_id="summary_trajectory_table")
    .partial(
        groupby_cols=["extra__name"],
        summary_params=[
            {
                "display_name": "Total Distance",
                "aggregator": "sum",
                "column": "dist_meters",
                "original_unit": "m",
                "new_unit": "km",
                "decimal_places": 2,
            }
        ],
        **summary_trajectory_table_params,
    )
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Persist Summary table

# %%
# parameters

save_summary_table_params = dict(
    filename=...,
)

# %%
# call the task


save_summary_table = (
    persist_df.handle_errors(task_instance_id="save_summary_table")
    .partial(
        filetype="csv",
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        **save_summary_table_params,
    )
    .mapvalues(argnames=["df"], argvalues=summary_trajectory_table)
)


# %% [markdown]
# ## Combine Map Layers

# %%
# parameters

combine_custom_map_layers_params = dict()

# %%
# call the task


combine_custom_map_layers = (
    combine_map_layers.handle_errors(task_instance_id="combine_custom_map_layers")
    .partial(static_layers=create_custom_map_layers, **combine_custom_map_layers_params)
    .mapvalues(argnames=["grouped_layers"], argvalues=traj_map_layers)
)


# %% [markdown]
# ## zoom by view state

# %%
# parameters

zoom_view_state_params = dict()

# %%
# call the task


zoom_view_state = (
    create_view_state_from_gdf.handle_errors(task_instance_id="zoom_view_state")
    .partial(pitch=0, bearing=0, **zoom_view_state_params)
    .mapvalues(argnames=["gdf"], argvalues=rename_speed_display_columns)
)


# %% [markdown]
# ## Zip layers and viewstate

# %%
# parameters

zip_layers_view_params = dict()

# %%
# call the task


zip_layers_view = (
    zip_grouped_by_key.handle_errors(task_instance_id="zip_layers_view")
    .partial(
        left=combine_custom_map_layers, right=zoom_view_state, **zip_layers_view_params
    )
    .call()
)


# %% [markdown]
# ## Draw Combined Ecomap

# %%
# parameters

draw_combined_ecomap_params = dict()

# %%
# call the task


draw_combined_ecomap = (
    draw_ecomap.handle_errors(task_instance_id="draw_combined_ecomap")
    .partial(
        tile_layers=base_map_defs,
        north_arrow_style={"placement": "top-left"},
        legend_style={"placement": "bottom-right", "title": "Speeds(Km/h)"},
        static=False,
        title=None,
        max_zoom=20,
        **draw_combined_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers", "view_state"], argvalues=zip_layers_view)
)


# %% [markdown]
# ## Persist ecomap as text

# %%
# parameters

ecomap_url_params = dict(
    filename=...,
)

# %%
# call the task


ecomap_url = (
    persist_text.handle_errors(task_instance_id="ecomap_url")
    .partial(root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"], **ecomap_url_params)
    .mapvalues(argnames=["text"], argvalues=draw_combined_ecomap)
)


# %% [markdown]
# ## Create SpeedMap Widget

# %%
# parameters

speed_map_widget_params = dict()

# %%
# call the task


speed_map_widget = (
    create_map_widget_single_view.handle_errors(task_instance_id="speed_map_widget")
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Speed Map", **speed_map_widget_params)
    .map(argnames=["view", "data"], argvalues=ecomap_url)
)


# %% [markdown]
# ## Merge Speedmap Widget Views

# %%
# parameters

td_grouped_map_widget_params = dict()

# %%
# call the task


td_grouped_map_widget = (
    merge_widget_views.handle_errors(task_instance_id="td_grouped_map_widget")
    .partial(widgets=speed_map_widget, **td_grouped_map_widget_params)
    .call()
)


# %% [markdown]
# ## LG Dashboard

# %%
# parameters

lg_dashboard_params = dict()

# %%
# call the task


lg_dashboard = (
    gather_dashboard.handle_errors(task_instance_id="lg_dashboard")
    .partial(
        details=workflow_details,
        widgets=td_grouped_map_widget,
        time_range=time_range,
        groupers=groupers,
        **lg_dashboard_params,
    )
    .call()
)
