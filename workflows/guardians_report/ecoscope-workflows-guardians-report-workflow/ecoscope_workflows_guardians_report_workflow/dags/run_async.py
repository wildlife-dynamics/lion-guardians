# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details
import json
import os

from ecoscope_workflows_core.graph import DependsOn, DependsOnSequence, Graph, Node
from ecoscope_workflows_core.tasks.analysis import (
    dataframe_column_max,
    dataframe_column_mean,
    dataframe_column_nunique,
    dataframe_column_sum,
)
from ecoscope_workflows_core.tasks.config import set_string_var, set_workflow_details
from ecoscope_workflows_core.tasks.filter import (
    get_timezone_from_time_range,
    set_time_range,
)
from ecoscope_workflows_core.tasks.groupby import groupbykey, set_groupers, split_groups
from ecoscope_workflows_core.tasks.io import persist_text, set_er_connection
from ecoscope_workflows_core.tasks.results import (
    create_map_widget_single_view,
    create_plot_widget_single_view,
    create_single_value_widget_single_view,
    gather_dashboard,
    merge_widget_views,
)
from ecoscope_workflows_core.tasks.skip import (
    all_keyed_iterables_are_skips,
    any_dependency_skipped,
    any_is_empty_df,
    never,
)
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index,
    convert_column_values_to_string,
    convert_values_to_timezone,
    map_columns,
    map_values_with_unit,
    sort_values,
    with_unit,
)
from ecoscope_workflows_ext_custom.tasks.io import html_to_png, load_df
from ecoscope_workflows_ext_custom.tasks.results import (
    create_path_layer,
    create_scatterplot_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.analysis import (
    calculate_linear_time_density,
    create_meshgrid,
    summarize_df,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_patrols_from_combined_params,
    persist_df,
    set_patrols_and_patrol_events_params,
    unpack_events_from_patrols_df_and_combined_params,
)
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    process_relocations,
    relocations_to_trajectory,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    draw_pie_chart,
    draw_time_series_bar_chart,
)
from ecoscope_workflows_ext_ecoscope.tasks.skip import all_geometry_are_none
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_color_map,
    apply_reloc_coord_filter,
    drop_nan_values_by_column,
)
from ecoscope_workflows_ext_lion_guardians.tasks import (
    add_totals_row,
    create_cover_context_page,
    create_geojson_layer,
    create_report_context,
    create_styled_layers_from_gdf,
    download_file_and_persist,
    draw_custom_map,
    extract_date_parts,
    flatten_tuple,
    get_event_type_display_names_from_events_aliased,
    get_patrol_observations_from_patrols_dataframe_and_combined_params,
    get_split_group_names,
    make_text_layer,
    merge_docx_files,
    merge_static_and_grouped_layers,
    print_output,
    set_custom_base_maps,
    view_state_deck_gdf,
    zip_lists,
)

from ..params import Params


def main(params: Params):
    params_dict = json.loads(params.model_dump_json(exclude_unset=True))

    dependencies = {
        "workflow_details": [],
        "time_range": [],
        "get_timezone": ["time_range"],
        "groupers": [],
        "er_client_name": [],
        "base_map_defs": [],
        "persist_ambo_gpkg": [],
        "persist_cover_page": [],
        "persist_indv_subject_page": [],
        "load_local_shapefiles": ["persist_ambo_gpkg"],
        "create_custom_map_layers": ["load_local_shapefiles"],
        "custom_text_layer": ["load_local_shapefiles"],
        "er_patrol_and_events_params": ["er_client_name", "time_range"],
        "prefetch_patrols": ["er_patrol_and_events_params"],
        "patrol_obs": ["prefetch_patrols", "er_patrol_and_events_params"],
        "patrol_events": ["prefetch_patrols", "er_patrol_and_events_params"],
        "event_type_display_names": ["er_client_name", "patrol_events"],
        "convert_patrols_to_user_timezone": ["patrol_obs", "get_timezone"],
        "convert_events_to_user_timezone": ["event_type_display_names", "get_timezone"],
        "persist_events_geoparquet": ["convert_events_to_user_timezone"],
        "set_patrol_traj_color_column": [],
        "patrol_reloc": ["convert_patrols_to_user_timezone"],
        "patrol_traj": ["patrol_reloc"],
        "traj_add_temporal_index": ["patrol_traj", "groupers"],
        "traj_rename_grouper_columns": ["traj_add_temporal_index"],
        "persist_patrols_geoparquet": ["traj_rename_grouper_columns"],
        "traj_colormap": [
            "traj_rename_grouper_columns",
            "set_patrol_traj_color_column",
        ],
        "filter_patrol_events": ["convert_events_to_user_timezone"],
        "pe_add_temporal_index": ["filter_patrol_events", "groupers"],
        "pe_colormap": ["pe_add_temporal_index"],
        "patrol_traj_cols_to_string": ["traj_colormap"],
        "pe_cols_to_string": ["pe_colormap"],
        "set_traj_pe_map_title": [],
        "set_ltd_map_title": [],
        "set_bar_chart_title": [],
        "set_pie_chart_title": [],
        "split_patrol_traj_groups": ["patrol_traj_cols_to_string", "groupers"],
        "split_pe_groups": ["pe_cols_to_string", "groupers"],
        "pe_rename_display_columns": ["split_pe_groups"],
        "patrol_events_map_layers": ["pe_rename_display_columns"],
        "speed_val_with_unit": ["split_patrol_traj_groups"],
        "patrol_traj_rename_columns": ["speed_val_with_unit"],
        "patrol_traj_map_layers": [
            "set_patrol_traj_color_column",
            "patrol_traj_rename_columns",
        ],
        "combined_traj_and_pe_map_layers": [
            "patrol_traj_map_layers",
            "patrol_events_map_layers",
        ],
        "merge_static_grouped_layers": [
            "create_custom_map_layers",
            "custom_text_layer",
            "combined_traj_and_pe_map_layers",
        ],
        "zoom_view_state": ["load_local_shapefiles"],
        "traj_patrol_events_ecomap": [
            "base_map_defs",
            "set_patrol_traj_color_column",
            "set_traj_pe_map_title",
            "zoom_view_state",
            "merge_static_grouped_layers",
        ],
        "traj_pe_ecomap_html_urls": ["traj_patrol_events_ecomap"],
        "traj_pe_map_widgets_single_views": [
            "set_traj_pe_map_title",
            "traj_pe_ecomap_html_urls",
        ],
        "traj_pe_grouped_map_widget": ["traj_pe_map_widgets_single_views"],
        "patrol_html_png": ["traj_pe_ecomap_html_urls"],
        "total_patrols": ["split_patrol_traj_groups"],
        "total_patrols_sv_widgets": ["total_patrols"],
        "total_patrols_grouped_sv_widget": ["total_patrols_sv_widgets"],
        "total_patrol_time": ["split_patrol_traj_groups"],
        "total_patrol_time_converted": ["total_patrol_time"],
        "total_patrol_time_sv_widgets": ["total_patrol_time_converted"],
        "patrol_time_grouped_widget": ["total_patrol_time_sv_widgets"],
        "total_patrol_dist": ["split_patrol_traj_groups"],
        "total_patrol_dist_converted": ["total_patrol_dist"],
        "total_patrol_dist_sv_widgets": ["total_patrol_dist_converted"],
        "patrol_dist_grouped_widget": ["total_patrol_dist_sv_widgets"],
        "avg_speed": ["split_patrol_traj_groups"],
        "average_speed_converted": ["avg_speed"],
        "avg_speed_sv_widgets": ["average_speed_converted"],
        "avg_speed_grouped_widget": ["avg_speed_sv_widgets"],
        "max_speed": ["split_patrol_traj_groups"],
        "max_speed_converted": ["max_speed"],
        "max_speed_sv_widgets": ["max_speed_converted"],
        "max_speed_grouped_widget": ["max_speed_sv_widgets"],
        "patrol_events_bar_chart": ["set_bar_chart_title", "split_pe_groups"],
        "patrol_events_bar_chart_html_url": ["patrol_events_bar_chart"],
        "patrol_events_bar_chart_widget": [
            "set_bar_chart_title",
            "patrol_events_bar_chart_html_url",
        ],
        "grouped_bar_plot_widget_merge": ["patrol_events_bar_chart_widget"],
        "patrol_bar_chart_png": ["patrol_events_bar_chart_html_url"],
        "patrol_events_pie_chart": ["set_pie_chart_title", "split_pe_groups"],
        "pe_pie_chart_html_urls": ["patrol_events_pie_chart"],
        "patrol_events_pie_chart_widgets": [
            "set_pie_chart_title",
            "pe_pie_chart_html_urls",
        ],
        "patrol_events_pie_widget_grouped": ["patrol_events_pie_chart_widgets"],
        "patrol_pie_chart_png": ["pe_pie_chart_html_urls"],
        "ltd_meshgrid": ["patrol_traj_cols_to_string"],
        "ltd": ["ltd_meshgrid", "split_patrol_traj_groups"],
        "drop_nan_percentiles": ["ltd"],
        "sort_percentile_values": ["drop_nan_percentiles"],
        "percentile_col_to_string": ["sort_percentile_values"],
        "td_colormap": ["percentile_col_to_string"],
        "patrol_td_rename_columns": ["td_colormap"],
        "td_map_layer": ["patrol_td_rename_columns"],
        "merged_time_density_layers": [
            "create_custom_map_layers",
            "custom_text_layer",
            "td_map_layer",
        ],
        "td_ecomap": [
            "base_map_defs",
            "set_ltd_map_title",
            "zoom_view_state",
            "merged_time_density_layers",
        ],
        "td_ecomap_html_url": ["td_ecomap"],
        "td_map_widget": ["set_ltd_map_title", "td_ecomap_html_url"],
        "td_grouped_map_widget": ["td_map_widget"],
        "td_html_png": ["td_ecomap_html_url"],
        "summarize_ranger_patrol": ["split_patrol_traj_groups"],
        "persist_ranger_patrol_efforts": ["summarize_ranger_patrol"],
        "summarized_patrol_types": ["split_patrol_traj_groups"],
        "add_total_patrol_summary": ["summarized_patrol_types"],
        "persist_patrol_types": ["add_total_patrol_summary"],
        "summarize_guardian_events": ["pe_rename_display_columns"],
        "persist_gua_patrol_efforts": ["summarize_guardian_events"],
        "summarized_event_types": ["pe_rename_display_columns"],
        "persist_event_tefforts": ["summarized_event_types"],
        "add_month_name": ["split_patrol_traj_groups"],
        "summarize_month_patrol": ["add_month_name"],
        "persist_month_patrol_efforts": ["summarize_month_patrol"],
        "context_cover_page": ["time_range", "persist_cover_page"],
        "report_context": [
            "persist_patrol_types",
            "patrol_html_png",
            "td_html_png",
            "patrol_pie_chart_png",
            "patrol_bar_chart_png",
            "persist_gua_patrol_efforts",
            "persist_event_tefforts",
            "persist_month_patrol_efforts",
            "persist_ranger_patrol_efforts",
        ],
        "print_report_ctx": ["report_context"],
        "flatten_context": ["report_context"],
        "get_grouper_names": ["split_patrol_traj_groups"],
        "zip_grouper_with_context": ["get_grouper_names", "flatten_context"],
        "flatten_final_report_context": ["zip_grouper_with_context"],
        "individual_report_context": [
            "persist_indv_subject_page",
            "flatten_final_report_context",
        ],
        "generate_report": ["context_cover_page", "individual_report_context"],
        "patrol_dashboard": [
            "workflow_details",
            "traj_pe_grouped_map_widget",
            "td_grouped_map_widget",
            "grouped_bar_plot_widget_merge",
            "patrol_events_pie_widget_grouped",
            "total_patrols_grouped_sv_widget",
            "patrol_time_grouped_widget",
            "patrol_dist_grouped_widget",
            "avg_speed_grouped_widget",
            "max_speed_grouped_widget",
            "groupers",
            "time_range",
        ],
    }

    nodes = {
        "workflow_details": Node(
            async_task=set_workflow_details.validate()
            .set_task_instance_id("workflow_details")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("workflow_details") or {}),
            method="call",
        ),
        "time_range": Node(
            async_task=set_time_range.validate()
            .set_task_instance_id("time_range")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "time_format": "%d %b %Y %H:%M:%S %Z",
                "timezone": {
                    "label": "UTC",
                    "tzCode": "UTC",
                    "name": "UTC",
                    "utc_offset": "+00:00",
                },
            }
            | (params_dict.get("time_range") or {}),
            method="call",
        ),
        "get_timezone": Node(
            async_task=get_timezone_from_time_range.validate()
            .set_task_instance_id("get_timezone")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "time_range": DependsOn("time_range"),
            }
            | (params_dict.get("get_timezone") or {}),
            method="call",
        ),
        "groupers": Node(
            async_task=set_groupers.validate()
            .set_task_instance_id("groupers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("groupers") or {}),
            method="call",
        ),
        "er_client_name": Node(
            async_task=set_er_connection.validate()
            .set_task_instance_id("er_client_name")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("er_client_name") or {}),
            method="call",
        ),
        "base_map_defs": Node(
            async_task=set_custom_base_maps.validate()
            .set_task_instance_id("base_map_defs")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("base_map_defs") or {}),
            method="call",
        ),
        "persist_ambo_gpkg": Node(
            async_task=download_file_and_persist.validate()
            .set_task_instance_id("persist_ambo_gpkg")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "url": "https://www.dropbox.com/scl/fi/phlc488gxqpcvr6ua3vk7/amboseli_group_ranch_boundaries.gpkg?rlkey=p5ztypwmj4ndjova9xe2ssiun&st=pknuicus&dl=0",
                "output_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "overwrite_existing": False,
                "retries": 3,
                "unzip": False,
            }
            | (params_dict.get("persist_ambo_gpkg") or {}),
            method="call",
        ),
        "persist_cover_page": Node(
            async_task=download_file_and_persist.validate()
            .set_task_instance_id("persist_cover_page")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "url": "https://www.dropbox.com/scl/fi/p1xk9no77w9ctpc4mnn6p/patrol_guardians_cover_page.docx?rlkey=tc5oo54s29wu7cz47glvlbcaj&st=9ivtf2k6&dl=0",
                "output_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "overwrite_existing": False,
                "retries": 3,
                "unzip": False,
            }
            | (params_dict.get("persist_cover_page") or {}),
            method="call",
        ),
        "persist_indv_subject_page": Node(
            async_task=download_file_and_persist.validate()
            .set_task_instance_id("persist_indv_subject_page")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "url": "https://www.dropbox.com/scl/fi/kp9mkc9dd5qbast86ufk4/custom_patrol_template.docx?rlkey=ea12bxesuu9dnnj1ngfahhqvr&st=ri5og7k8&dl=0",
                "output_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "overwrite_existing": False,
                "retries": 3,
                "unzip": False,
            }
            | (params_dict.get("persist_indv_subject_page") or {}),
            method="call",
        ),
        "load_local_shapefiles": Node(
            async_task=load_df.validate()
            .set_task_instance_id("load_local_shapefiles")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "file_path": DependsOn("persist_ambo_gpkg"),
                "layer": None,
                "deserialize_json": False,
            }
            | (params_dict.get("load_local_shapefiles") or {}),
            method="call",
        ),
        "create_custom_map_layers": Node(
            async_task=create_styled_layers_from_gdf.validate()
            .set_task_instance_id("create_custom_map_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "gdf": DependsOn("load_local_shapefiles"),
                "filename": "amboseli_group_ranch_boundaries",
                "style_config": {
                    "styles": {
                        "stroked": True,
                        "filled": False,
                        "get_elevation": 50,
                        "opacity": 0.75,
                        "get_line_color": [105, 105, 105, 200],
                        "get_line_width": 3.75,
                    },
                    "legend": {
                        "label": ["Group ranch boundaries"],
                        "color": ["#696969"],
                    },
                },
            }
            | (params_dict.get("create_custom_map_layers") or {}),
            method="call",
        ),
        "custom_text_layer": Node(
            async_task=make_text_layer.validate()
            .set_task_instance_id("custom_text_layer")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "txt_gdf": DependsOn("load_local_shapefiles"),
                "label_column": "R_NAME",
                "fallback_columns": ["name", "title"],
                "use_centroid": True,
                "color": [0, 0, 0, 255],
                "size": 65,
                "font_family": "Calibri",
                "font_weight": "bold",
                "background": False,
                "background_color": None,
                "background_padding": None,
                "text_anchor": "start",
                "alignment_baseline": "bottom",
                "billboard": True,
                "pickable": True,
                "tooltip_columns": ["label"],
                "target_crs": "epsg:4326",
            }
            | (params_dict.get("custom_text_layer") or {}),
            method="call",
        ),
        "er_patrol_and_events_params": Node(
            async_task=set_patrols_and_patrol_events_params.validate()
            .set_task_instance_id("er_patrol_and_events_params")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "client": DependsOn("er_client_name"),
                "time_range": DependsOn("time_range"),
                "include_patrol_details": True,
                "raise_on_empty": False,
                "truncate_to_time_range": True,
                "sub_page_size": 150,
            }
            | (params_dict.get("er_patrol_and_events_params") or {}),
            method="call",
        ),
        "prefetch_patrols": Node(
            async_task=get_patrols_from_combined_params.validate()
            .set_task_instance_id("prefetch_patrols")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "combined_params": DependsOn("er_patrol_and_events_params"),
            }
            | (params_dict.get("prefetch_patrols") or {}),
            method="call",
        ),
        "patrol_obs": Node(
            async_task=get_patrol_observations_from_patrols_dataframe_and_combined_params.validate()
            .set_task_instance_id("patrol_obs")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "patrols_df": DependsOn("prefetch_patrols"),
                "combined_params": DependsOn("er_patrol_and_events_params"),
            }
            | (params_dict.get("patrol_obs") or {}),
            method="call",
        ),
        "patrol_events": Node(
            async_task=unpack_events_from_patrols_df_and_combined_params.validate()
            .set_task_instance_id("patrol_events")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "patrols_df": DependsOn("prefetch_patrols"),
                "combined_params": DependsOn("er_patrol_and_events_params"),
            }
            | (params_dict.get("patrol_events") or {}),
            method="call",
        ),
        "event_type_display_names": Node(
            async_task=get_event_type_display_names_from_events_aliased.validate()
            .set_task_instance_id("event_type_display_names")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "client": DependsOn("er_client_name"),
                "events_gdf": DependsOn("patrol_events"),
                "append_category_names": "duplicates",
            }
            | (params_dict.get("event_type_display_names") or {}),
            method="call",
        ),
        "convert_patrols_to_user_timezone": Node(
            async_task=convert_values_to_timezone.validate()
            .set_task_instance_id("convert_patrols_to_user_timezone")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("patrol_obs"),
                "timezone": DependsOn("get_timezone"),
                "columns": ["patrol_start_time", "patrol_end_time", "fixtime"],
            }
            | (params_dict.get("convert_patrols_to_user_timezone") or {}),
            method="call",
        ),
        "convert_events_to_user_timezone": Node(
            async_task=convert_values_to_timezone.validate()
            .set_task_instance_id("convert_events_to_user_timezone")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("event_type_display_names"),
                "timezone": DependsOn("get_timezone"),
                "columns": ["time", "patrol_start_time"],
            }
            | (params_dict.get("convert_events_to_user_timezone") or {}),
            method="call",
        ),
        "persist_events_geoparquet": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_events_geoparquet")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filetype": "geoparquet",
                "df": DependsOn("convert_events_to_user_timezone"),
                "filename": "events",
            }
            | (params_dict.get("persist_events_geoparquet") or {}),
            method="call",
        ),
        "set_patrol_traj_color_column": Node(
            async_task=set_string_var.validate()
            .set_task_instance_id("set_patrol_traj_color_column")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("set_patrol_traj_color_column") or {}),
            method="call",
        ),
        "patrol_reloc": Node(
            async_task=process_relocations.validate()
            .set_task_instance_id("patrol_reloc")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "observations": DependsOn("convert_patrols_to_user_timezone"),
                "relocs_columns": [
                    "patrol_id",
                    "patrol_start_time",
                    "patrol_end_time",
                    "patrol_type__value",
                    "patrol_type__display",
                    "patrol_serial_number",
                    "patrol_status",
                    "patrol_subject",
                    "groupby_col",
                    "fixtime",
                    "junk_status",
                    "extra__source",
                    "geometry",
                ],
                "filter_point_coords": [
                    {"x": 180.0, "y": 90.0},
                    {"x": 0.0, "y": 0.0},
                    {"x": 1.0, "y": 1.0},
                ],
            }
            | (params_dict.get("patrol_reloc") or {}),
            method="call",
        ),
        "patrol_traj": Node(
            async_task=relocations_to_trajectory.validate()
            .set_task_instance_id("patrol_traj")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "relocations": DependsOn("patrol_reloc"),
            }
            | (params_dict.get("patrol_traj") or {}),
            method="call",
        ),
        "traj_add_temporal_index": Node(
            async_task=add_temporal_index.validate()
            .set_task_instance_id("traj_add_temporal_index")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("patrol_traj"),
                "time_col": "extra__patrol_start_time",
                "groupers": DependsOn("groupers"),
                "cast_to_datetime": True,
                "format": "mixed",
            }
            | (params_dict.get("traj_add_temporal_index") or {}),
            method="call",
        ),
        "traj_rename_grouper_columns": Node(
            async_task=map_columns.validate()
            .set_task_instance_id("traj_rename_grouper_columns")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("traj_add_temporal_index"),
                "drop_columns": [],
                "retain_columns": [],
                "rename_columns": {
                    "extra__patrol_type__value": "patrol_type",
                    "extra__patrol_serial_number": "patrol_serial_number",
                    "extra__patrol_status": "patrol_status",
                    "extra__patrol_subject": "patrol_subject",
                },
            }
            | (params_dict.get("traj_rename_grouper_columns") or {}),
            method="call",
        ),
        "persist_patrols_geoparquet": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_patrols_geoparquet")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filetype": "geoparquet",
                "df": DependsOn("traj_rename_grouper_columns"),
                "filename": "trajectories",
            }
            | (params_dict.get("persist_patrols_geoparquet") or {}),
            method="call",
        ),
        "traj_colormap": Node(
            async_task=apply_color_map.validate()
            .set_task_instance_id("traj_colormap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("traj_rename_grouper_columns"),
                "colormap": "Paired",
                "input_column_name": DependsOn("set_patrol_traj_color_column"),
                "output_column_name": "patrol_traj_colormap",
            }
            | (params_dict.get("traj_colormap") or {}),
            method="call",
        ),
        "filter_patrol_events": Node(
            async_task=apply_reloc_coord_filter.validate()
            .set_task_instance_id("filter_patrol_events")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("convert_events_to_user_timezone"),
                "roi_gdf": None,
                "roi_name": None,
            }
            | (params_dict.get("filter_patrol_events") or {}),
            method="call",
        ),
        "pe_add_temporal_index": Node(
            async_task=add_temporal_index.validate()
            .set_task_instance_id("pe_add_temporal_index")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("filter_patrol_events"),
                "time_col": "patrol_start_time",
                "groupers": DependsOn("groupers"),
                "cast_to_datetime": True,
                "format": "mixed",
            }
            | (params_dict.get("pe_add_temporal_index") or {}),
            method="call",
        ),
        "pe_colormap": Node(
            async_task=apply_color_map.validate()
            .set_task_instance_id("pe_colormap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("pe_add_temporal_index"),
                "input_column_name": "event_type",
                "colormap": "Accent",
                "output_column_name": "event_type_colormap",
            }
            | (params_dict.get("pe_colormap") or {}),
            method="call",
        ),
        "patrol_traj_cols_to_string": Node(
            async_task=convert_column_values_to_string.validate()
            .set_task_instance_id("patrol_traj_cols_to_string")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("traj_colormap"),
                "columns": ["patrol_serial_number", "patrol_type"],
            }
            | (params_dict.get("patrol_traj_cols_to_string") or {}),
            method="call",
        ),
        "pe_cols_to_string": Node(
            async_task=convert_column_values_to_string.validate()
            .set_task_instance_id("pe_cols_to_string")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("pe_colormap"),
                "columns": ["patrol_serial_number", "patrol_type"],
            }
            | (params_dict.get("pe_cols_to_string") or {}),
            method="call",
        ),
        "set_traj_pe_map_title": Node(
            async_task=set_string_var.validate()
            .set_task_instance_id("set_traj_pe_map_title")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "var": "Trajectories & Patrol Events Map",
            }
            | (params_dict.get("set_traj_pe_map_title") or {}),
            method="call",
        ),
        "set_ltd_map_title": Node(
            async_task=set_string_var.validate()
            .set_task_instance_id("set_ltd_map_title")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "var": "Time Density Map",
            }
            | (params_dict.get("set_ltd_map_title") or {}),
            method="call",
        ),
        "set_bar_chart_title": Node(
            async_task=set_string_var.validate()
            .set_task_instance_id("set_bar_chart_title")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "var": "Patrol Events Bar Chart",
            }
            | (params_dict.get("set_bar_chart_title") or {}),
            method="call",
        ),
        "set_pie_chart_title": Node(
            async_task=set_string_var.validate()
            .set_task_instance_id("set_pie_chart_title")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "var": "Patrol Events Pie Chart",
            }
            | (params_dict.get("set_pie_chart_title") or {}),
            method="call",
        ),
        "split_patrol_traj_groups": Node(
            async_task=split_groups.validate()
            .set_task_instance_id("split_patrol_traj_groups")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("patrol_traj_cols_to_string"),
                "groupers": DependsOn("groupers"),
            }
            | (params_dict.get("split_patrol_traj_groups") or {}),
            method="call",
        ),
        "split_pe_groups": Node(
            async_task=split_groups.validate()
            .set_task_instance_id("split_pe_groups")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "df": DependsOn("pe_cols_to_string"),
                "groupers": DependsOn("groupers"),
            }
            | (params_dict.get("split_pe_groups") or {}),
            method="call",
        ),
        "pe_rename_display_columns": Node(
            async_task=map_columns.validate()
            .set_task_instance_id("pe_rename_display_columns")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "drop_columns": [],
                "retain_columns": [],
                "rename_columns": {
                    "patrol_serial_number": "Patrol Serial",
                    "serial_number": "Event Serial",
                    "event_type_display": "Event Type",
                    "time": "Event Time",
                },
            }
            | (params_dict.get("pe_rename_display_columns") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_pe_groups"),
            },
        ),
        "patrol_events_map_layers": Node(
            async_task=create_scatterplot_layer.validate()
            .set_task_instance_id("patrol_events_map_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                    all_geometry_are_none,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "get_fill_color": "event_type_colormap",
                    "get_radius": 5,
                    "opacity": 0.55,
                    "stroked": True,
                },
                "legend": None,
            }
            | (params_dict.get("patrol_events_map_layers") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["geodataframe"],
                "argvalues": DependsOn("pe_rename_display_columns"),
            },
        ),
        "speed_val_with_unit": Node(
            async_task=map_values_with_unit.validate()
            .set_task_instance_id("speed_val_with_unit")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "input_column_name": "speed_kmhr",
                "output_column_name": "speed_kmhr",
                "original_unit": "km/h",
                "new_unit": "km/h",
                "decimal_places": 1,
            }
            | (params_dict.get("speed_val_with_unit") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "patrol_traj_rename_columns": Node(
            async_task=map_columns.validate()
            .set_task_instance_id("patrol_traj_rename_columns")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "drop_columns": [],
                "retain_columns": [],
                "rename_columns": {
                    "patrol_serial_number": "Patrol Serial",
                    "extra__patrol_type__display": "Patrol Type",
                    "segment_start": "Start",
                    "timespan_seconds": "Duration (s)",
                    "speed_kmhr": "Speed (kph)",
                },
            }
            | (params_dict.get("patrol_traj_rename_columns") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("speed_val_with_unit"),
            },
        ),
        "patrol_traj_map_layers": Node(
            async_task=create_path_layer.validate()
            .set_task_instance_id("patrol_traj_map_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                    all_geometry_are_none,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "get_color": "patrol_traj_colormap",
                    "get_width": 1.85,
                    "width_scale": 1,
                    "width_min_pixels": 2,
                    "width_max_pixels": 6,
                    "width_units": "pixels",
                    "cap_rounded": True,
                    "joint_rounded": True,
                    "billboard": False,
                    "opacity": 0.55,
                    "stroked": True,
                },
                "legend": {
                    "label_column": DependsOn("set_patrol_traj_color_column"),
                    "color_column": "patrol_traj_colormap",
                },
            }
            | (params_dict.get("patrol_traj_map_layers") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["geodataframe"],
                "argvalues": DependsOn("patrol_traj_rename_columns"),
            },
        ),
        "combined_traj_and_pe_map_layers": Node(
            async_task=groupbykey.validate()
            .set_task_instance_id("combined_traj_and_pe_map_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    all_keyed_iterables_are_skips,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "iterables": DependsOnSequence(
                    [
                        DependsOn("patrol_traj_map_layers"),
                        DependsOn("patrol_events_map_layers"),
                    ],
                ),
            }
            | (params_dict.get("combined_traj_and_pe_map_layers") or {}),
            method="call",
        ),
        "merge_static_grouped_layers": Node(
            async_task=merge_static_and_grouped_layers.validate()
            .set_task_instance_id("merge_static_grouped_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "static_layers": DependsOnSequence(
                    [
                        DependsOn("create_custom_map_layers"),
                        DependsOn("custom_text_layer"),
                    ],
                ),
            }
            | (params_dict.get("merge_static_grouped_layers") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["grouped_layers"],
                "argvalues": DependsOn("combined_traj_and_pe_map_layers"),
            },
        ),
        "zoom_view_state": Node(
            async_task=view_state_deck_gdf.validate()
            .set_task_instance_id("zoom_view_state")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "pitch": 0,
                "bearing": 0,
                "gdf": DependsOn("load_local_shapefiles"),
            }
            | (params_dict.get("zoom_view_state") or {}),
            method="call",
        ),
        "traj_patrol_events_ecomap": Node(
            async_task=draw_custom_map.validate()
            .set_task_instance_id("traj_patrol_events_ecomap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "tile_layers": DependsOn("base_map_defs"),
                "legend_style": {
                    "title": DependsOn("set_patrol_traj_color_column"),
                    "placement": "bottom-right",
                },
                "static": False,
                "title": None,
                "max_zoom": 15,
                "widget_id": DependsOn("set_traj_pe_map_title"),
                "view_state": DependsOn("zoom_view_state"),
            }
            | (params_dict.get("traj_patrol_events_ecomap") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["geo_layers"],
                "argvalues": DependsOn("merge_static_grouped_layers"),
            },
        ),
        "traj_pe_ecomap_html_urls": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("traj_pe_ecomap_html_urls")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "patrols_ecomap",
            }
            | (params_dict.get("traj_pe_ecomap_html_urls") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["text"],
                "argvalues": DependsOn("traj_patrol_events_ecomap"),
            },
        ),
        "traj_pe_map_widgets_single_views": Node(
            async_task=create_map_widget_single_view.validate()
            .set_task_instance_id("traj_pe_map_widgets_single_views")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": DependsOn("set_traj_pe_map_title"),
            }
            | (params_dict.get("traj_pe_map_widgets_single_views") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("traj_pe_ecomap_html_urls"),
            },
        ),
        "traj_pe_grouped_map_widget": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("traj_pe_grouped_map_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("traj_pe_map_widgets_single_views"),
            }
            | (params_dict.get("traj_pe_grouped_map_widget") or {}),
            method="call",
        ),
        "patrol_html_png": Node(
            async_task=html_to_png.validate()
            .set_task_instance_id("patrol_html_png")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "output_dir": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "config": {"wait_for_timeout": 20000},
            }
            | (params_dict.get("patrol_html_png") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["html_path"],
                "argvalues": DependsOn("traj_pe_ecomap_html_urls"),
            },
        ),
        "total_patrols": Node(
            async_task=dataframe_column_nunique.validate()
            .set_task_instance_id("total_patrols")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "extra__patrol_id",
            }
            | (params_dict.get("total_patrols") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "total_patrols_sv_widgets": Node(
            async_task=create_single_value_widget_single_view.validate()
            .set_task_instance_id("total_patrols_sv_widgets")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": "Total Patrols",
                "decimal_places": 1,
            }
            | (params_dict.get("total_patrols_sv_widgets") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("total_patrols"),
            },
        ),
        "total_patrols_grouped_sv_widget": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("total_patrols_grouped_sv_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("total_patrols_sv_widgets"),
            }
            | (params_dict.get("total_patrols_grouped_sv_widget") or {}),
            method="call",
        ),
        "total_patrol_time": Node(
            async_task=dataframe_column_sum.validate()
            .set_task_instance_id("total_patrol_time")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "timespan_seconds",
            }
            | (params_dict.get("total_patrol_time") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "total_patrol_time_converted": Node(
            async_task=with_unit.validate()
            .set_task_instance_id("total_patrol_time_converted")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "original_unit": "s",
                "new_unit": "h",
            }
            | (params_dict.get("total_patrol_time_converted") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["value"],
                "argvalues": DependsOn("total_patrol_time"),
            },
        ),
        "total_patrol_time_sv_widgets": Node(
            async_task=create_single_value_widget_single_view.validate()
            .set_task_instance_id("total_patrol_time_sv_widgets")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": "Total Time",
                "decimal_places": 1,
            }
            | (params_dict.get("total_patrol_time_sv_widgets") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("total_patrol_time_converted"),
            },
        ),
        "patrol_time_grouped_widget": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("patrol_time_grouped_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("total_patrol_time_sv_widgets"),
            }
            | (params_dict.get("patrol_time_grouped_widget") or {}),
            method="call",
        ),
        "total_patrol_dist": Node(
            async_task=dataframe_column_sum.validate()
            .set_task_instance_id("total_patrol_dist")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "dist_meters",
            }
            | (params_dict.get("total_patrol_dist") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "total_patrol_dist_converted": Node(
            async_task=with_unit.validate()
            .set_task_instance_id("total_patrol_dist_converted")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "original_unit": "m",
                "new_unit": "km",
            }
            | (params_dict.get("total_patrol_dist_converted") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["value"],
                "argvalues": DependsOn("total_patrol_dist"),
            },
        ),
        "total_patrol_dist_sv_widgets": Node(
            async_task=create_single_value_widget_single_view.validate()
            .set_task_instance_id("total_patrol_dist_sv_widgets")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": "Total Distance",
                "decimal_places": 1,
            }
            | (params_dict.get("total_patrol_dist_sv_widgets") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("total_patrol_dist_converted"),
            },
        ),
        "patrol_dist_grouped_widget": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("patrol_dist_grouped_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("total_patrol_dist_sv_widgets"),
            }
            | (params_dict.get("patrol_dist_grouped_widget") or {}),
            method="call",
        ),
        "avg_speed": Node(
            async_task=dataframe_column_mean.validate()
            .set_task_instance_id("avg_speed")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "speed_kmhr",
            }
            | (params_dict.get("avg_speed") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "average_speed_converted": Node(
            async_task=with_unit.validate()
            .set_task_instance_id("average_speed_converted")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "original_unit": "km/h",
                "new_unit": "km/h",
            }
            | (params_dict.get("average_speed_converted") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["value"],
                "argvalues": DependsOn("avg_speed"),
            },
        ),
        "avg_speed_sv_widgets": Node(
            async_task=create_single_value_widget_single_view.validate()
            .set_task_instance_id("avg_speed_sv_widgets")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": "Average Speed",
                "decimal_places": 1,
            }
            | (params_dict.get("avg_speed_sv_widgets") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("average_speed_converted"),
            },
        ),
        "avg_speed_grouped_widget": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("avg_speed_grouped_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("avg_speed_sv_widgets"),
            }
            | (params_dict.get("avg_speed_grouped_widget") or {}),
            method="call",
        ),
        "max_speed": Node(
            async_task=dataframe_column_max.validate()
            .set_task_instance_id("max_speed")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "speed_kmhr",
            }
            | (params_dict.get("max_speed") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "max_speed_converted": Node(
            async_task=with_unit.validate()
            .set_task_instance_id("max_speed_converted")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "original_unit": "km/h",
                "new_unit": "km/h",
            }
            | (params_dict.get("max_speed_converted") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["value"],
                "argvalues": DependsOn("max_speed"),
            },
        ),
        "max_speed_sv_widgets": Node(
            async_task=create_single_value_widget_single_view.validate()
            .set_task_instance_id("max_speed_sv_widgets")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": "Max Speed",
                "decimal_places": 1,
            }
            | (params_dict.get("max_speed_sv_widgets") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("max_speed_converted"),
            },
        ),
        "max_speed_grouped_widget": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("max_speed_grouped_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("max_speed_sv_widgets"),
            }
            | (params_dict.get("max_speed_grouped_widget") or {}),
            method="call",
        ),
        "patrol_events_bar_chart": Node(
            async_task=draw_time_series_bar_chart.validate()
            .set_task_instance_id("patrol_events_bar_chart")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "x_axis": "time",
                "y_axis": "event_type_display",
                "category": "event_type_display",
                "agg_function": "count",
                "color_column": "event_type_colormap",
                "plot_style": {"xperiodalignment": "middle"},
                "layout_style": None,
                "widget_id": DependsOn("set_bar_chart_title"),
            }
            | (params_dict.get("patrol_events_bar_chart") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["dataframe"],
                "argvalues": DependsOn("split_pe_groups"),
            },
        ),
        "patrol_events_bar_chart_html_url": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("patrol_events_bar_chart_html_url")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "patrol_events_time_series_bar_chart",
            }
            | (params_dict.get("patrol_events_bar_chart_html_url") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["text"],
                "argvalues": DependsOn("patrol_events_bar_chart"),
            },
        ),
        "patrol_events_bar_chart_widget": Node(
            async_task=create_plot_widget_single_view.validate()
            .set_task_instance_id("patrol_events_bar_chart_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": DependsOn("set_bar_chart_title"),
            }
            | (params_dict.get("patrol_events_bar_chart_widget") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("patrol_events_bar_chart_html_url"),
            },
        ),
        "grouped_bar_plot_widget_merge": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("grouped_bar_plot_widget_merge")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("patrol_events_bar_chart_widget"),
            }
            | (params_dict.get("grouped_bar_plot_widget_merge") or {}),
            method="call",
        ),
        "patrol_bar_chart_png": Node(
            async_task=html_to_png.validate()
            .set_task_instance_id("patrol_bar_chart_png")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "output_dir": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "config": {"wait_for_timeout": 1000},
            }
            | (params_dict.get("patrol_bar_chart_png") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["html_path"],
                "argvalues": DependsOn("patrol_events_bar_chart_html_url"),
            },
        ),
        "patrol_events_pie_chart": Node(
            async_task=draw_pie_chart.validate()
            .set_task_instance_id("patrol_events_pie_chart")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "value_column": "event_type_display",
                "plot_style": {"textinfo": "value"},
                "label_column": None,
                "color_column": "event_type_colormap",
                "layout_style": None,
                "widget_id": DependsOn("set_pie_chart_title"),
            }
            | (params_dict.get("patrol_events_pie_chart") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["dataframe"],
                "argvalues": DependsOn("split_pe_groups"),
            },
        ),
        "pe_pie_chart_html_urls": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("pe_pie_chart_html_urls")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "patrols_pie_chart",
            }
            | (params_dict.get("pe_pie_chart_html_urls") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["text"],
                "argvalues": DependsOn("patrol_events_pie_chart"),
            },
        ),
        "patrol_events_pie_chart_widgets": Node(
            async_task=create_plot_widget_single_view.validate()
            .set_task_instance_id("patrol_events_pie_chart_widgets")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": DependsOn("set_pie_chart_title"),
            }
            | (params_dict.get("patrol_events_pie_chart_widgets") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("pe_pie_chart_html_urls"),
            },
        ),
        "patrol_events_pie_widget_grouped": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("patrol_events_pie_widget_grouped")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("patrol_events_pie_chart_widgets"),
            }
            | (params_dict.get("patrol_events_pie_widget_grouped") or {}),
            method="call",
        ),
        "patrol_pie_chart_png": Node(
            async_task=html_to_png.validate()
            .set_task_instance_id("patrol_pie_chart_png")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "output_dir": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "config": {"wait_for_timeout": 1000},
            }
            | (params_dict.get("patrol_pie_chart_png") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["html_path"],
                "argvalues": DependsOn("pe_pie_chart_html_urls"),
            },
        ),
        "ltd_meshgrid": Node(
            async_task=create_meshgrid.validate()
            .set_task_instance_id("ltd_meshgrid")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "aoi": DependsOn("patrol_traj_cols_to_string"),
                "intersecting_only": False,
            }
            | (params_dict.get("ltd_meshgrid") or {}),
            method="call",
        ),
        "ltd": Node(
            async_task=calculate_linear_time_density.validate()
            .set_task_instance_id("ltd")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "meshgrid": DependsOn("ltd_meshgrid"),
                "percentiles": [50.0, 60.0, 70.0, 80.0, 90.0, 100.0],
            }
            | (params_dict.get("ltd") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["trajectory_gdf"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "drop_nan_percentiles": Node(
            async_task=drop_nan_values_by_column.validate()
            .set_task_instance_id("drop_nan_percentiles")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "percentile",
            }
            | (params_dict.get("drop_nan_percentiles") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("ltd"),
            },
        ),
        "sort_percentile_values": Node(
            async_task=sort_values.validate()
            .set_task_instance_id("sort_percentile_values")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "column_name": "percentile",
                "ascending": True,
                "na_position": "last",
            }
            | (params_dict.get("sort_percentile_values") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("drop_nan_percentiles"),
            },
        ),
        "percentile_col_to_string": Node(
            async_task=convert_column_values_to_string.validate()
            .set_task_instance_id("percentile_col_to_string")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "columns": ["percentile"],
            }
            | (params_dict.get("percentile_col_to_string") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("sort_percentile_values"),
            },
        ),
        "td_colormap": Node(
            async_task=apply_color_map.validate()
            .set_task_instance_id("td_colormap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "input_column_name": "percentile",
                "colormap": "RdYlGn",
                "output_column_name": "percentile_colormap",
            }
            | (params_dict.get("td_colormap") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("percentile_col_to_string"),
            },
        ),
        "patrol_td_rename_columns": Node(
            async_task=map_columns.validate()
            .set_task_instance_id("patrol_td_rename_columns")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "drop_columns": [],
                "retain_columns": [],
                "rename_columns": {"percentile": "Percentile"},
            }
            | (params_dict.get("patrol_td_rename_columns") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("td_colormap"),
            },
        ),
        "td_map_layer": Node(
            async_task=create_geojson_layer.validate()
            .set_task_instance_id("td_map_layer")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                    all_geometry_are_none,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "layer_style": {
                    "get_fill_color": "percentile_colormap",
                    "opacity": 0.45,
                    "get_line_width": 0.75,
                    "stroked": True,
                },
                "legend": {
                    "label_column": "Percentile",
                    "color_column": "percentile_colormap",
                },
            }
            | (params_dict.get("td_map_layer") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["geodataframe"],
                "argvalues": DependsOn("patrol_td_rename_columns"),
            },
        ),
        "merged_time_density_layers": Node(
            async_task=merge_static_and_grouped_layers.validate()
            .set_task_instance_id("merged_time_density_layers")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "static_layers": DependsOnSequence(
                    [
                        DependsOn("create_custom_map_layers"),
                        DependsOn("custom_text_layer"),
                    ],
                ),
            }
            | (params_dict.get("merged_time_density_layers") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["grouped_layers"],
                "argvalues": DependsOn("td_map_layer"),
            },
        ),
        "td_ecomap": Node(
            async_task=draw_custom_map.validate()
            .set_task_instance_id("td_ecomap")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "tile_layers": DependsOn("base_map_defs"),
                "legend_style": {"title": "Time Spent", "placement": "bottom-right"},
                "static": False,
                "title": None,
                "max_zoom": 15,
                "widget_id": DependsOn("set_ltd_map_title"),
                "view_state": DependsOn("zoom_view_state"),
            }
            | (params_dict.get("td_ecomap") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["geo_layers"],
                "argvalues": DependsOn("merged_time_density_layers"),
            },
        ),
        "td_ecomap_html_url": Node(
            async_task=persist_text.validate()
            .set_task_instance_id("td_ecomap_html_url")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename_suffix": "time_density",
            }
            | (params_dict.get("td_ecomap_html_url") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["text"],
                "argvalues": DependsOn("td_ecomap"),
            },
        ),
        "td_map_widget": Node(
            async_task=create_map_widget_single_view.validate()
            .set_task_instance_id("td_map_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    never,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "title": DependsOn("set_ltd_map_title"),
            }
            | (params_dict.get("td_map_widget") or {}),
            method="map",
            kwargs={
                "argnames": ["view", "data"],
                "argvalues": DependsOn("td_ecomap_html_url"),
            },
        ),
        "td_grouped_map_widget": Node(
            async_task=merge_widget_views.validate()
            .set_task_instance_id("td_grouped_map_widget")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "widgets": DependsOn("td_map_widget"),
            }
            | (params_dict.get("td_grouped_map_widget") or {}),
            method="call",
        ),
        "td_html_png": Node(
            async_task=html_to_png.validate()
            .set_task_instance_id("td_html_png")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "output_dir": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "config": {"wait_for_timeout": 20000},
            }
            | (params_dict.get("td_html_png") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["html_path"],
                "argvalues": DependsOn("td_ecomap_html_url"),
            },
        ),
        "summarize_ranger_patrol": Node(
            async_task=summarize_df.validate()
            .set_task_instance_id("summarize_ranger_patrol")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "groupby_cols": ["patrol_subject"],
                "reset_index": True,
                "summary_params": [
                    {
                        "display_name": "no_of_patrols",
                        "aggregator": "nunique",
                        "column": "extra__patrol_id",
                    },
                    {
                        "display_name": "total_distance",
                        "aggregator": "sum",
                        "column": "dist_meters",
                        "original_unit": "m",
                        "new_unit": "km",
                    },
                    {
                        "display_name": "total_time",
                        "aggregator": "sum",
                        "column": "timespan_seconds",
                        "original_unit": "s",
                        "new_unit": "h",
                    },
                ],
            }
            | (params_dict.get("summarize_ranger_patrol") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "persist_ranger_patrol_efforts": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_ranger_patrol_efforts")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filetype": "csv",
            }
            | (params_dict.get("persist_ranger_patrol_efforts") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("summarize_ranger_patrol"),
            },
        ),
        "summarized_patrol_types": Node(
            async_task=summarize_df.validate()
            .set_task_instance_id("summarized_patrol_types")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "groupby_cols": ["patrol_type"],
                "reset_index": True,
                "summary_params": [
                    {
                        "display_name": "no_of_patrols",
                        "aggregator": "nunique",
                        "column": "extra__patrol_id",
                    },
                    {
                        "display_name": "total_distance",
                        "aggregator": "sum",
                        "column": "dist_meters",
                        "original_unit": "m",
                        "new_unit": "km",
                    },
                    {
                        "display_name": "total_time",
                        "aggregator": "sum",
                        "column": "timespan_seconds",
                        "original_unit": "s",
                        "new_unit": "h",
                    },
                ],
            }
            | (params_dict.get("summarized_patrol_types") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "add_total_patrol_summary": Node(
            async_task=add_totals_row.validate()
            .set_task_instance_id("add_total_patrol_summary")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "label_col": "patrol_type",
                "label": "Total",
            }
            | (params_dict.get("add_total_patrol_summary") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("summarized_patrol_types"),
            },
        ),
        "persist_patrol_types": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_patrol_types")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filetype": "csv",
            }
            | (params_dict.get("persist_patrol_types") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("add_total_patrol_summary"),
            },
        ),
        "summarize_guardian_events": Node(
            async_task=summarize_df.validate()
            .set_task_instance_id("summarize_guardian_events")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "groupby_cols": ["patrol_subject"],
                "reset_index": True,
                "summary_params": [
                    {
                        "display_name": "no_of_events",
                        "aggregator": "nunique",
                        "column": "id",
                    }
                ],
            }
            | (params_dict.get("summarize_guardian_events") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("pe_rename_display_columns"),
            },
        ),
        "persist_gua_patrol_efforts": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_gua_patrol_efforts")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filetype": "csv",
            }
            | (params_dict.get("persist_gua_patrol_efforts") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("summarize_guardian_events"),
            },
        ),
        "summarized_event_types": Node(
            async_task=summarize_df.validate()
            .set_task_instance_id("summarized_event_types")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "groupby_cols": ["event_type"],
                "reset_index": True,
                "summary_params": [
                    {
                        "display_name": "no_of_events",
                        "aggregator": "nunique",
                        "column": "id",
                    }
                ],
            }
            | (params_dict.get("summarized_event_types") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("pe_rename_display_columns"),
            },
        ),
        "persist_event_tefforts": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_event_tefforts")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filetype": "csv",
            }
            | (params_dict.get("persist_event_tefforts") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("summarized_event_types"),
            },
        ),
        "add_month_name": Node(
            async_task=extract_date_parts.validate()
            .set_task_instance_id("add_month_name")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "date_column": "extra__patrol_start_time",
                "parts": ["month", "day", "month_name"],
            }
            | (params_dict.get("add_month_name") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("split_patrol_traj_groups"),
            },
        ),
        "summarize_month_patrol": Node(
            async_task=summarize_df.validate()
            .set_task_instance_id("summarize_month_patrol")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "groupby_cols": ["month_name"],
                "reset_index": True,
                "summary_params": [
                    {
                        "display_name": "no_of_patrols",
                        "aggregator": "nunique",
                        "column": "extra__patrol_id",
                    },
                    {
                        "display_name": "total_distance",
                        "aggregator": "sum",
                        "column": "dist_meters",
                        "original_unit": "m",
                        "new_unit": "km",
                    },
                    {
                        "display_name": "total_time",
                        "aggregator": "sum",
                        "column": "timespan_seconds",
                        "original_unit": "s",
                        "new_unit": "h",
                    },
                ],
            }
            | (params_dict.get("summarize_month_patrol") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("add_month_name"),
            },
        ),
        "persist_month_patrol_efforts": Node(
            async_task=persist_df.validate()
            .set_task_instance_id("persist_month_patrol_efforts")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "root_path": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filetype": "csv",
            }
            | (params_dict.get("persist_month_patrol_efforts") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["df"],
                "argvalues": DependsOn("summarize_month_patrol"),
            },
        ),
        "context_cover_page": Node(
            async_task=create_cover_context_page.validate()
            .set_task_instance_id("context_cover_page")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "report_period": DependsOn("time_range"),
                "prepared_by": "Ecoscope",
                "template_path": DependsOn("persist_cover_page"),
                "output_directory": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "filename": "cover_page.docx",
            }
            | (params_dict.get("context_cover_page") or {}),
            method="call",
        ),
        "report_context": Node(
            async_task=groupbykey.validate()
            .set_task_instance_id("report_context")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    all_keyed_iterables_are_skips,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "iterables": DependsOnSequence(
                    [
                        DependsOn("persist_patrol_types"),
                        DependsOn("patrol_html_png"),
                        DependsOn("td_html_png"),
                        DependsOn("patrol_pie_chart_png"),
                        DependsOn("patrol_bar_chart_png"),
                        DependsOn("persist_gua_patrol_efforts"),
                        DependsOn("persist_event_tefforts"),
                        DependsOn("persist_month_patrol_efforts"),
                        DependsOn("persist_ranger_patrol_efforts"),
                    ],
                ),
            }
            | (params_dict.get("report_context") or {}),
            method="call",
        ),
        "print_report_ctx": Node(
            async_task=print_output.validate()
            .set_task_instance_id("print_report_ctx")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("print_report_ctx") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["value"],
                "argvalues": DependsOn("report_context"),
            },
        ),
        "flatten_context": Node(
            async_task=flatten_tuple.validate()
            .set_task_instance_id("flatten_context")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("flatten_context") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["nested"],
                "argvalues": DependsOn("report_context"),
            },
        ),
        "get_grouper_names": Node(
            async_task=get_split_group_names.validate()
            .set_task_instance_id("get_grouper_names")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "split_data": DependsOn("split_patrol_traj_groups"),
            }
            | (params_dict.get("get_grouper_names") or {}),
            method="call",
        ),
        "zip_grouper_with_context": Node(
            async_task=zip_lists.validate()
            .set_task_instance_id("zip_grouper_with_context")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "left": DependsOn("get_grouper_names"),
                "right": DependsOn("flatten_context"),
            }
            | (params_dict.get("zip_grouper_with_context") or {}),
            method="call",
        ),
        "flatten_final_report_context": Node(
            async_task=flatten_tuple.validate()
            .set_task_instance_id("flatten_final_report_context")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial=(params_dict.get("flatten_final_report_context") or {}),
            method="mapvalues",
            kwargs={
                "argnames": ["nested"],
                "argvalues": DependsOn("zip_grouper_with_context"),
            },
        ),
        "individual_report_context": Node(
            async_task=create_report_context.validate()
            .set_task_instance_id("individual_report_context")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "filename": None,
                "validate_images": True,
                "box_h_cm": 9.0,
                "box_w_cm": 15.0,
                "template_path": DependsOn("persist_indv_subject_page"),
                "output_directory": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
            }
            | (params_dict.get("individual_report_context") or {}),
            method="mapvalues",
            kwargs={
                "argnames": [
                    "grouper_type",
                    "grouper_eq",
                    "grouper_value",
                    "patrol_type_effort_path",
                    "patrol_events_track_map",
                    "patrol_time_density_map",
                    "events_pie_chart",
                    "events_time_series_bar_chart",
                    "patrol_events",
                    "event_efforts",
                    "month_stats",
                    "guardian_stats",
                ],
                "argvalues": DependsOn("flatten_final_report_context"),
            },
        ),
        "generate_report": Node(
            async_task=merge_docx_files.validate()
            .set_task_instance_id("generate_report")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "cover_page_path": DependsOn("context_cover_page"),
                "output_directory": os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
                "context_page_items": DependsOn("individual_report_context"),
                "filename": "lg_guardians_report.docx",
            }
            | (params_dict.get("generate_report") or {}),
            method="call",
        ),
        "patrol_dashboard": Node(
            async_task=gather_dashboard.validate()
            .set_task_instance_id("patrol_dashboard")
            .handle_errors()
            .with_tracing()
            .skipif(
                conditions=[
                    any_is_empty_df,
                    any_dependency_skipped,
                ],
                unpack_depth=1,
            )
            .set_executor("lithops"),
            partial={
                "details": DependsOn("workflow_details"),
                "widgets": DependsOnSequence(
                    [
                        DependsOn("traj_pe_grouped_map_widget"),
                        DependsOn("td_grouped_map_widget"),
                        DependsOn("grouped_bar_plot_widget_merge"),
                        DependsOn("patrol_events_pie_widget_grouped"),
                        DependsOn("total_patrols_grouped_sv_widget"),
                        DependsOn("patrol_time_grouped_widget"),
                        DependsOn("patrol_dist_grouped_widget"),
                        DependsOn("avg_speed_grouped_widget"),
                        DependsOn("max_speed_grouped_widget"),
                    ],
                ),
                "groupers": DependsOn("groupers"),
                "time_range": DependsOn("time_range"),
            }
            | (params_dict.get("patrol_dashboard") or {}),
            method="call",
        ),
    }
    graph = Graph(dependencies=dependencies, nodes=nodes)
    results = graph.execute()
    return results
